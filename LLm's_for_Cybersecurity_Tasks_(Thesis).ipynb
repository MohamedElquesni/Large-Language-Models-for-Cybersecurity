{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedElquesni/Large-Language-Models-for-Cybersecurity/blob/main/LLm's_for_Cybersecurity_Tasks_(Thesis).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmaICAAyOfx0"
      },
      "source": [
        "# ğŸ§  Fine-Tuning LLMs for Cybersecurity Tasks using Unsloth\n",
        "\n",
        "This notebook demonstrates how to fine-tune various decoder-based LLMs (e.g., `Mistral`, `DeepSeek`, etc.) using the [Unsloth](https://github.com/unslothai/unsloth) library with QLoRA (4-bit) for efficient, low-resource training.\n",
        "\n",
        "We'll apply this to a range of cybersecurity tasks, including:\n",
        "\n",
        "- ğŸ“§ Phishing Email Detection\n",
        "- ğŸ“„ Log Anomaly Detection\n",
        "- ğŸ§  Threat Intelligence Extraction\n",
        "- ğŸš¨ Automated Incident Response\n",
        "- ğŸ” Threat Hunting Reasoning\n",
        "\n",
        "We'll use:\n",
        "- ğŸ¦¥ **Unsloth** for resource-efficient LLM fine-tuning\n",
        "- ğŸ’¾ Optional GGUF export for deployment with Ollama or llama.cpp\n",
        "- âš™ï¸ Modular architecture to support different LLMs per task (e.g., Mistral for phishing, DeepSeek for log analysis, etc.)\n",
        "\n",
        "> ğŸ› ï¸ Note: You can set the model of choice per domain by configuring the `MODEL_NAME` and `DOMAIN` in the setup section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I - ğŸ“§ Email Phishing Detection â€“ Mistral-7B Prompt Engineering & Inference\n",
        "\n",
        "This section focuses on using `Mistral-7B` to detect phishing emails through **prompt engineering**, without any fine-tuning or training.\n",
        "\n",
        "The model is prompted to return **structured JSON responses** with the following fields:\n",
        "- `\"Is_Phishing\"`: Whether the email is phishing (true/false)\n",
        "- `\"Risk\"`: Risk level â€“ High, Medium, or Low\n",
        "- `\"Suspicious_Links\"`: Any suspicious links present\n",
        "- `\"Social_Engineering_Elements\"`: Techniques like urgency, fear, enticement, impersonation, etc.\n",
        "- `\"Actions\"`: Recommended next steps (e.g., delete, report, ignore)\n",
        "- `\"Reason\"`: Brief explanation for the decision\n",
        "\n",
        "This is a **zero-shot / few-shot inference setup**, designed to verify the modelâ€™s phishing detection performance using crafted prompts.\n",
        "\n",
        "ğŸ” No fine-tuning, training, or model weight modification is done. The focus is strictly on prompt engineering and evaluation through inference.\n"
      ],
      "metadata": {
        "id": "iMUViDglUDl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ§± Section 1 â€“ Complete Setup (Install, Load, Patch, Test)\n",
        "\n",
        "This section sets up the environment for **prompt-based inference** using the `Mistral-7B` model.\n",
        "\n",
        "It includes:\n",
        "\n",
        "1. Installing required dependencies\n",
        "2. Loading the `Mistral-7B` model (4-bit or other optimized format)\n",
        "3. Patching or configuring inference settings (if needed)\n",
        "4. Testing the model with a basic phishing detection prompt\n",
        "\n",
        "âœ… Run this once per session to initialize the environment for **prompt engineering and phishing detection inference**.\n",
        "\n",
        "âš ï¸ No fine-tuning, LoRA, QLoRA, or training is performed in this notebook. The focus is purely on zero-shot or few-shot **inference and evaluation**.\n"
      ],
      "metadata": {
        "id": "imuZlNpJVz5K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Zxsy4BPA9c"
      },
      "source": [
        "### ğŸ“¦ 1.1 â€“ Install Dependencies\n",
        "\n",
        "We'll begin by installing the required libraries to run **Mistral-7B** for phishing detection using **prompt engineering only**.\n",
        "\n",
        "This installs:\n",
        "- `transformers` for loading the Mistral-7B model  \n",
        "- `bitsandbytes` for efficient 4-bit model loading (optional)  \n",
        "- `accelerate` for device handling  \n",
        "- `torch` for GPU support  \n",
        "\n",
        "No training, fine-tuning, or adapter loading is required â€” this setup is for **inference only**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IOg02LZXPE93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486267ee-fd8b-452a-b23b-9923c4635824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# âœ… Clean install for inference-only use (no training tools)\n",
        "!pip install -q transformers accelerate bitsandbytes torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“¦ 1.2 â€“ Load the Mistral-7B Model for Inference\n",
        "\n",
        "In this step, we load the `Mistral-7B-Instruct-v0.2` model from Hugging Face in 4-bit precision using the `transformers` library.\n",
        "\n",
        "This model is used **only for inference** â€” no fine-tuning or LoRA adapter loading is involved.\n",
        "\n",
        "We also configure padding tokens and device placement (CPU/GPU) for smooth operation in Google Colab.\n"
      ],
      "metadata": {
        "id": "UaavFWW0hBEM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f-nKO4JyPXn3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "333b3e9d7735400a8ad97f0f6025d96d",
            "cf13d79f97914ad992b0cfad5df8e90a",
            "f0ae4bff45cd42a88cdac453150b1f8b",
            "aded7e968a584b1eac9a2f3709d1b02d",
            "330bd12d9d3a45fc87e50adad276739d",
            "e4f001d160164663ba3a03c4ce991be3",
            "f8a3b8c9fb9045559aea802fd1cb88de",
            "371b3f75f00c434daacbce493e99ea2a",
            "47e219e42cb441c581d49af3925d731b",
            "1fe213b7cdb8438f85cd6e27c270db9e",
            "389004b705dd40149df67dae243966d3",
            "c5ffa24ba26f421cbc8bd6011d2b0372",
            "b596788178dc49af87cc176efa61de4c",
            "828512fad88d4e5bad12685ba4f74359",
            "e138ad2c07eb4ac285087cdc90e55fe1",
            "7ce0d531f73a4d30bd4d8ab7d41415b9",
            "77a34bfa6b004c7684552e43a02c80e5",
            "d781437ee00443aba2d01a71b1cc1131",
            "8fdf7279e28644d4b0430f35b7d04757",
            "c10e8ba69dd04fdbaeab7933b8eb56fe",
            "74d28f814b5d4c9fb410788ccf9c263d",
            "3369fa1af6cc4fb0822cc0d796c7eabe",
            "521dd20ca4bc462ebf5aa852e9cf71ae",
            "fa1aa6a384634044adce493f46ee3b56",
            "ff4c0db6726d4884b43410bd247cf4ad",
            "946e859edee848b88ca00e0b7fb1ad31",
            "155efaf089c445879dcd03739cdb3909",
            "873f9c34aa6442bd8366c69d73a1bed7",
            "c5cb7f0863f64ff8a58c278140bb7b8b",
            "5c7b66dad5c34109b44db0d50098dc18",
            "c081f69e7255487ea7cb49392d3c4671",
            "17227db628b64614bc8b99a0b40d35e4",
            "705e3fde92e541c98321346486670f5c",
            "8e786b87a4dd4b6ca9e6edad672ee149",
            "64afbf39f26c4016a9ea44ad4fbb389f",
            "f179d13bafd84965b245a8ad9df9cd24",
            "77ecaf44afbb47f9b071d8e43395ce97",
            "ecce06ad660f4c50834598d27c830731",
            "320bfbecfd49467aa4654c380e8483ba",
            "39776ac2b4e74d3aad5e7af6574833b1",
            "71f817877fbd4c63929754e1dadfed7f",
            "7c89cd14812d405099be715ef2dffa24",
            "2fc83457376342fca76ac9940ed5d762",
            "f88c249f869e4540b50254ce9b914090",
            "3a6908d000ad41cf9de97f9d3d495a0e",
            "0d4c95a3c87e4f7b93dd47b1e7910b7c",
            "069d140614e24b7a91d5d72c004fbc09",
            "31a13e2fbaed45f9bf4cf19fae19522f",
            "bace069490bb4cdb9ab240e472f715fa",
            "bd48d62d1c2a46e288434700cd79b0dc",
            "d6d7ce1a97b244f9bd42439ef65de0cb",
            "ce54d246723242719fac1b1c5b117c52",
            "04d14484a58449ed972a469dde1b64ae",
            "c7fad0c668124c50bdefed809fd5322a",
            "87d76f2620f04c789654f8e45bf126b5",
            "5e8c99d9066d43f8864d233caf20a091",
            "c8c9fba57bdf4bca9ea15a068bde2778",
            "41f2651db12c46299e9ed3fa4bd69919",
            "1aac90379f874c36acb9d3f0e00cf12c",
            "35b0eae09c5940faa259d0033d76166d",
            "2a981c003aa3406984a29354abcf8b9e",
            "9811499857804620880ab7c205380f3c",
            "de9288ffab4b48bbbab3b06c853f3ab0",
            "7d14fd00f4b24519b9a5ee4960e8251e",
            "3a0ca01a88514c1699ff9452c67dcb19",
            "29a4452cf9fb4729b379490a503948a5",
            "e838a521d01d4fddbc6441bbd5e9fc81",
            "653f82f4bc6f4747a9d2b3b02eeb24b8",
            "34c1066c37954cacb0c455d4ba9619df",
            "6e293a74191b48299f2f25815e455239",
            "dae2dda3b7064795bf5e96edbcf79390",
            "47a2a0adfda7490fbc33acff8564f69a",
            "d02039fa9b8b4e4395c2a12368a3fe8c",
            "a92571421bd54f808fed1c07cad611b0",
            "509229ee597c40418a2dd8efdead4365",
            "3698470463e04fe2982395da9d9dc70c",
            "e280aef45ef9435392448ed4479bb111"
          ]
        },
        "outputId": "1eddfa9d-f698-45a0-eccf-3d4c6daa5b18"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "333b3e9d7735400a8ad97f0f6025d96d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5ffa24ba26f421cbc8bd6011d2b0372"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "521dd20ca4bc462ebf5aa852e9cf71ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e786b87a4dd4b6ca9e6edad672ee149"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a6908d000ad41cf9de97f9d3d495a0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:212: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.14G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e8c99d9066d43f8864d233caf20a091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/157 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e838a521d01d4fddbc6441bbd5e9fc81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Mistral-7B loaded successfully and ready for inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# âœ… Choose the official Mistral 7B Instruct model\n",
        "model_name = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load the model (4-bit for memory efficiency)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
        "    load_in_4bit=True  # âœ… Optional: Uses bitsandbytes\n",
        ")\n",
        "\n",
        "# Configure tokenizer padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "\n",
        "print(\"âœ… Mistral-7B loaded successfully and ready for inference.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§ª 1.3 â€“ Test the Model Before Training\n",
        "\n",
        "Now that the `Mistral-Small-Instruct-2409` model is loaded and patched with LoRA, letâ€™s test how it responds *before* any fine-tuning.\n",
        "\n",
        "This helps you:\n",
        "- âœ… Confirm the model and tokenizer are working end-to-end  \n",
        "- ğŸ“Š Get a baseline (pre-trained) response to your phishing prompt  \n",
        "- ğŸ› Debug any issues with prompt formatting or tokenization\n"
      ],
      "metadata": {
        "id": "8EmD-75fViZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from torch import inference_mode\n",
        "\n",
        "# Sample phishing email\n",
        "email_body = \"\"\"From: notifications@corpfiles.com\n",
        "Subject: Shared Document â€“ Q2 Budget Final.xlsx\n",
        "\n",
        "Hi,\n",
        "\n",
        "John has shared a document with you:\n",
        "ğŸ“ **Q2 Budget Final.xlsx**\n",
        "\n",
        "You can access it securely here:\n",
        "http://corpfiles.com/download/Q2BudgetFinal\n",
        "\n",
        "Please review before tomorrowâ€™s meeting.\n",
        "\n",
        "Best regards,\n",
        "Finance Department\n",
        "\"\"\"\n",
        "\n",
        "# Instruction-based phishing detection prompt\n",
        "prompt = f\"\"\"### Instruction:\n",
        "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
        "\n",
        "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
        "\n",
        "- A link to a document/file from an unfamiliar or suspicious domain (e.g. fake Google Drive, Dropbox, corpfiles.net instead of corpfile.com)\n",
        "- Urgent language or pressure to act quickly\n",
        "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
        "- Requests to click, download, or input sensitive data\n",
        "- Email sender addresses mimicking known brands or internal departments\n",
        "- Unexpected attachments or shared documents\n",
        "- Impersonation of executives, HR, IT, or Finance\n",
        "- Spelling mistakes or inconsistencies in formatting\n",
        "\n",
        "### Respond in **this exact JSON format**:\n",
        "{{\n",
        "  \"Is_Phishing\": boolean,\n",
        "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
        "  \"Suspicious_Links\": [\"...\"],\n",
        "  \"Social_Engineering_Elements\": [\"...\"],\n",
        "  \"Actions\": [\"...\"],\n",
        "  \"Reason\": \"...\"\n",
        "}}\n",
        "\n",
        "### Email:\n",
        "{email_body}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ğŸ” Run model inference\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "with inference_mode():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.0,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "# ğŸ§  Full decoded output\n",
        "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"\\nğŸ§  Full Raw Output:\\n\")\n",
        "print(decoded_output)\n",
        "\n",
        "# âœ… Extract the last JSON object using regex\n",
        "matches = list(re.finditer(r\"\\{[\\s\\S]+?\\}\", decoded_output))\n",
        "if matches:\n",
        "    clean_json = matches[-1].group()\n",
        "    print(\"\\nâœ… Extracted JSON Only:\\n\")\n",
        "    print(clean_json)\n",
        "else:\n",
        "    print(\"\\nâš ï¸ Could not extract JSON block cleanly.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi-e4AF_VkPp",
        "outputId": "6536d0c2-96f8-4e19-daf3-9270aeaed5a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  Full Raw Output:\n",
            "\n",
            "### Instruction:\n",
            "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
            "\n",
            "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
            "\n",
            "- A link to a document/file from an unfamiliar or suspicious domain (e.g. fake Google Drive, Dropbox, corpfiles.net instead of corpfile.com)\n",
            "- Urgent language or pressure to act quickly\n",
            "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
            "- Requests to click, download, or input sensitive data\n",
            "- Email sender addresses mimicking known brands or internal departments\n",
            "- Unexpected attachments or shared documents\n",
            "- Impersonation of executives, HR, IT, or Finance\n",
            "- Spelling mistakes or inconsistencies in formatting\n",
            "\n",
            "### Respond in **this exact JSON format**:\n",
            "{\n",
            "  \"Is_Phishing\": boolean,\n",
            "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
            "  \"Suspicious_Links\": [\"...\"],\n",
            "  \"Social_Engineering_Elements\": [\"...\"],\n",
            "  \"Actions\": [\"...\"],\n",
            "  \"Reason\": \"...\"\n",
            "}\n",
            "\n",
            "### Email:\n",
            "From: notifications@corpfiles.com\n",
            "Subject: Shared Document â€“ Q2 Budget Final.xlsx\n",
            "\n",
            "Hi,\n",
            "\n",
            "John has shared a document with you:\n",
            "ğŸ“ **Q2 Budget Final.xlsx**\n",
            "\n",
            "You can access it securely here:\n",
            "http://corpfiles.com/download/Q2BudgetFinal\n",
            "\n",
            "Please review before tomorrowâ€™s meeting.\n",
            "\n",
            "Best regards,\n",
            "Finance Department\n",
            "\n",
            "\n",
            "### Response:\n",
            "{\n",
            "  \"Is_Phishing\": true,\n",
            "  \"Risk\": \"High\",\n",
            "  \"Suspicious_Links\": [\"http://corpfiles.com/download/Q2BudgetFinal\"],\n",
            "  \"Social_Engineering_Elements\": [\"Generic greeting\", \"Request to download a file\"],\n",
            "  \"Actions\": [\"Block the link\", \"Inform the Finance Department about the suspicious email\", \"Investigate the sender's email address\"],\n",
            "  \"Reason\": \"The email is from an unfamiliar domain, contains a generic greeting, and requests to download a file. These elements suggest a high risk of phishing.\"\n",
            "}\n",
            "\n",
            "âœ… Extracted JSON Only:\n",
            "\n",
            "{\n",
            "  \"Is_Phishing\": true,\n",
            "  \"Risk\": \"High\",\n",
            "  \"Suspicious_Links\": [\"http://corpfiles.com/download/Q2BudgetFinal\"],\n",
            "  \"Social_Engineering_Elements\": [\"Generic greeting\", \"Request to download a file\"],\n",
            "  \"Actions\": [\"Block the link\", \"Inform the Finance Department about the suspicious email\", \"Investigate the sender's email address\"],\n",
            "  \"Reason\": \"The email is from an unfamiliar domain, contains a generic greeting, and requests to download a file. These elements suggest a high risk of phishing.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ§ª Section 2 â€“ Phishing Email Detection with Structured JSON Output\n",
        "\n",
        "This section benchmarks the `Mistral-7B` model on phishing email detection using **prompt engineering only**. The model operates in a zero-shot setting to analyze email content and return structured JSON responses that are easily machine-readableâ€”ideal for integration into automated workflows within a Security Operations Center (SOC).\n",
        "\n",
        "The full evaluation pipeline consists of:\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“¥ Dataset Handling\n",
        "\n",
        "We begin by uploading a phishing dataset and computing high-level statistics. The dataset is previewed, and a structured prompt is dynamically generated for each email sample.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¤– Inference via Prompt Engineering\n",
        "\n",
        "Each email is embedded into a standardized prompt that instructs the model to analyze the message and respond in a **strict JSON format**, such as:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"Is_Phishing\": true,\n",
        "  \"Risk\": \"High\",\n",
        "  \"Suspicious_Links\": [\"...\"],\n",
        "  \"Social_Engineering_Elements\": [\"...\"],\n",
        "  \"Actions\": [\"...\"],\n",
        "  \"Reason\": \"...\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "AorGpdk2eD9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 ğŸ—‚ï¸ Dataset: `UTwente` (Binary Email Classification)\n",
        "\n",
        "This dataset contains labeled email samples for phishing detection. Each sample includes the full email content and a binary label indicating whether the email is safe or malicious.\n",
        "\n",
        "Each entry consists of:\n",
        "- `Email Text`: the complete email body, potentially including subject lines\n",
        "- `Email Type`: the true classification of the email:\n",
        "  - `Phishing Email` â†’ malicious\n",
        "  - `Safe Email` â†’ legitimate\n",
        "\n",
        "This dataset is already preprocessed and balanced across the two classes. Once uploaded, we will:\n",
        "- Map the labels to binary values (1 = phishing, 0 = safe)\n",
        "- Count phishing vs. safe samples\n",
        "- Preview sample emails\n",
        "- Generate structured prompts for zero-shot model inference\n",
        "- Compare the model's predictions to ground truth in a later step\n"
      ],
      "metadata": {
        "id": "CnhjSm-9x8No"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1 ğŸ—‚ï¸ Upload and Load the Phishing Dataset\n",
        "\n",
        "In this step, we upload a phishing detection dataset containing labeled email samples for evaluation.\n",
        "\n",
        "The dataset must include the following columns:\n",
        "- **`Email Text`**: the full content of the email (subject + body)\n",
        "- **`Email Type`**: ground truth labels as either:\n",
        "  - `Phishing Email` â†’ malicious\n",
        "  - `Safe Email` â†’ legitimate\n",
        "\n",
        "Once uploaded, we will load the data into memory and inspect its structure (row count, column names) to confirm it is ready for processing.\n"
      ],
      "metadata": {
        "id": "O_D-xKfuKXSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ğŸ§  Section 2.2.1 â€“ Benchmarking: Phishing Detection with Structured Output (Inference-Only)\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# ğŸ“¤ Step 1: Upload the dataset\n",
        "print(\"ğŸ“¤ Please upload your phishing dataset with 'Email Text' and 'Email Type' columns.\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# âœ… Step 2: Load dataset\n",
        "df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "print(f\"\\nâœ… Dataset loaded: {file_name}\")\n",
        "print(f\"ğŸ“¦ Rows: {len(df)} | Columns: {df.columns.tolist()}\")\n"
      ],
      "metadata": {
        "id": "VZ8cVLlCKXiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2 ğŸ§  Preprocess Dataset and Generate Structured Prompts\n",
        "\n",
        "Next, we preprocess the dataset by:\n",
        "- Renaming columns for consistency\n",
        "- Mapping label values to binary format (`1` = phishing, `0` = safe)\n",
        "\n",
        "We then construct a **structured prompt** for each email. These prompts instruct the model to analyze the email and return a standardized JSON response, containing:\n",
        "\n",
        "- `Is_Phishing`: true or false\n",
        "- `Risk`: level of severity\n",
        "- `Suspicious_Links`: list of flagged links\n",
        "- `Social_Engineering_Elements`: manipulative techniques found\n",
        "- `Actions`: recommended security steps\n",
        "- `Reason`: rationale for the decision\n",
        "\n",
        "Finally, we preview the full prompt for one randomly selected phishing email to verify correctness before running model inference.\n"
      ],
      "metadata": {
        "id": "gRWh0TxcKp48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# âœ… Step 3: Preprocess labels and columns\n",
        "df = df.rename(columns={\"Email Text\": \"text\", \"Email Type\": \"label\"})\n",
        "df[\"label\"] = df[\"label\"].map({\"Phishing Email\": 1, \"Safe Email\": 0})\n",
        "\n",
        "# âœ… Step 4: Generate structured prompts\n",
        "def build_prompt(email_body):\n",
        "    return f\"\"\"### Instruction:\n",
        "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
        "\n",
        "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
        "\n",
        "- A link to a document/file from an unfamiliar or suspicious domain (e.g. fake Google Drive, Dropbox, corpfiles.net instead of corpfile.com)\n",
        "- Urgent language or pressure to act quickly\n",
        "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
        "- Requests to click, download, or input sensitive data\n",
        "- Email sender addresses mimicking known brands or internal departments\n",
        "- Unexpected attachments or shared documents\n",
        "- Impersonation of executives, HR, IT, or Finance\n",
        "- Spelling mistakes or inconsistencies in formatting\n",
        "\n",
        "### Respond in **this exact JSON format**:\n",
        "{{\n",
        "  \"Is_Phishing\": boolean,\n",
        "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
        "  \"Suspicious_Links\": [\"...\"],\n",
        "  \"Social_Engineering_Elements\": [\"...\"],\n",
        "  \"Actions\": [\"...\"],\n",
        "  \"Reason\": \"...\"\n",
        "}}\n",
        "\n",
        "### Email:\n",
        "{email_body}\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "df[\"prompt\"] = df[\"text\"].apply(build_prompt)\n",
        "\n",
        "# âœ… Step 5: Display label distribution\n",
        "print(f\"\\nğŸŸ¢ Phishing Emails: {df['label'].sum()}\")\n",
        "print(f\"ğŸ”µ Legitimate Emails: {len(df) - df['label'].sum()}\")\n",
        "\n",
        "# ğŸ§ª Step 6: Show full prompt for one phishing email\n",
        "sample_index = df[df[\"label\"] == 1].sample(1, random_state=42).index[0]\n",
        "print(\"\\nğŸ“Œ Full Prompt Example (Phishing Email):\\n\")\n",
        "print(df.loc[sample_index, \"prompt\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "r-XuxxpFeJ77",
        "outputId": "c65be0a0-70f0-4841-c049-dece0b5784e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¤ Please upload your phishing dataset with 'Email Text' and 'Email Type' columns.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-79717ecb-eb17-407f-8419-b526fff53353\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-79717ecb-eb17-407f-8419-b526fff53353\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Phishing_validation_emails.csv to Phishing_validation_emails (2).csv\n",
            "\n",
            "âœ… Dataset loaded: Phishing_validation_emails (2).csv\n",
            "ğŸ“¦ Rows: 2000 | Columns: ['Email Text', 'Email Type']\n",
            "\n",
            "ğŸŸ¢ Phishing Emails: 1000\n",
            "ğŸ”µ Legitimate Emails: 1000\n",
            "\n",
            "ğŸ“Œ Full Prompt Example (Phishing Email):\n",
            "\n",
            "### Instruction:\n",
            "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
            "\n",
            "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
            "\n",
            "- A link to a document/file from an unfamiliar or suspicious domain (e.g. fake Google Drive, Dropbox, corpfiles.net instead of corpfile.com)\n",
            "- Urgent language or pressure to act quickly\n",
            "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
            "- Requests to click, download, or input sensitive data\n",
            "- Email sender addresses mimicking known brands or internal departments\n",
            "- Unexpected attachments or shared documents\n",
            "- Impersonation of executives, HR, IT, or Finance\n",
            "- Spelling mistakes or inconsistencies in formatting\n",
            "\n",
            "### Respond in **this exact JSON format**:\n",
            "{\n",
            "  \"Is_Phishing\": boolean,\n",
            "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
            "  \"Suspicious_Links\": [\"...\"],\n",
            "  \"Social_Engineering_Elements\": [\"...\"],\n",
            "  \"Actions\": [\"...\"],\n",
            "  \"Reason\": \"...\"\n",
            "}\n",
            "\n",
            "### Email:\n",
            "Your subscription is about to expire. Renew now to continue enjoying our services.\n",
            "\n",
            "### Response:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3 ğŸ¤– Run Batched Inference and Extract Structured JSON Output\n",
        "\n",
        "In this step, we run **batched inference** using the loaded model (e.g., Mistral-7B) to process structured prompts and generate phishing detection outputs in JSON format.\n",
        "\n",
        "The process involves:\n",
        "- Tokenizing prompts with padding and truncation\n",
        "- Running the model in batches using `inference_mode()` for efficiency\n",
        "- Decoding the modelâ€™s raw output into readable text\n",
        "- Extracting the JSON response block using a regular expression\n",
        "- Parsing each JSON block into Python dictionaries for downstream analysis\n",
        "\n",
        "Each result is appended to the DataFrame under the `model_output` column for later evaluation against ground truth labels.\n",
        "\n",
        "> âš ï¸ Note: The generation is zero-shot; the model has not been fine-tuned on phishing-specific data.\n"
      ],
      "metadata": {
        "id": "QECFa-ZBLPoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import inference_mode\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import json\n",
        "\n",
        "batch_size = 16\n",
        "max_prompt_length = 1024  # Optional: Lower if still slow\n",
        "all_predictions = []\n",
        "\n",
        "print(f\"ğŸ” Running batched inference (batch size = {batch_size})...\")\n",
        "\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    batch_prompts = df[\"prompt\"].iloc[i:i+batch_size].tolist()\n",
        "\n",
        "    # Tokenize with truncation\n",
        "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_prompt_length).to(\"cuda\")\n",
        "\n",
        "    with inference_mode():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=384,\n",
        "            temperature=0.0,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    # Extract JSON from each response\n",
        "    for decoded in decoded_outputs:\n",
        "        matches = list(re.finditer(r\"\\{[\\s\\S]+?\\}\", decoded))\n",
        "        json_text = matches[-1].group() if matches else \"\"\n",
        "        try:\n",
        "            parsed = json.loads(json_text) if json_text else {\"error\": \"no_json_found\", \"raw\": decoded}\n",
        "        except:\n",
        "            parsed = {\"error\": \"invalid_json\", \"raw\": decoded}\n",
        "        all_predictions.append(parsed)\n",
        "\n",
        "df[\"model_output\"] = all_predictions\n",
        "print(\"âœ… Batched inference complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1il1kTNhn4sZ",
        "outputId": "99753627-fc7f-44a6-ba9e-e8cfd88980b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Running batched inference (batch size = 16)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [31:47<00:00, 15.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Batched inference complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.4 ğŸ“Š Inference Results Summary\n",
        "\n",
        "After running zero-shot inference on the full phishing email dataset using Mistral-7B, the model produced structured JSON outputs for all 2,000 examples without any parsing failures.\n",
        "\n",
        "The following performance metrics were calculated based on the modelâ€™s `\"Is_Phishing\"` predictions vs. ground truth labels (`1` for phishing, `0` for legitimate):\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NbZnm3g6yaNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# âœ… Extract model-predicted labels\n",
        "def extract_prediction(obj):\n",
        "    if isinstance(obj, dict) and \"Is_Phishing\" in obj:\n",
        "        return int(obj[\"Is_Phishing\"]) if isinstance(obj[\"Is_Phishing\"], bool) else None\n",
        "    return None\n",
        "\n",
        "df[\"predicted_label\"] = df[\"model_output\"].apply(extract_prediction)\n",
        "\n",
        "# âœ… Filter out rows where prediction failed\n",
        "valid = df.dropna(subset=[\"predicted_label\"])\n",
        "y_true = valid[\"label\"]\n",
        "y_pred = valid[\"predicted_label\"]\n",
        "\n",
        "# âœ… Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# âœ… Summary\n",
        "print(\"ğŸ“Š Evaluation Metrics (on valid responses):\")\n",
        "print(f\"ğŸ§® Accuracy : {accuracy:.4f}\")\n",
        "print(f\"âœ… Precision: {precision:.4f}\")\n",
        "print(f\"ğŸ” Recall   : {recall:.4f}\")\n",
        "print(f\"â­ F1 Score : {f1:.4f}\")\n",
        "print(f\"\\nğŸ“¦ Valid Predictions: {len(valid)} / {len(df)} total\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m5XMsj7wpf1",
        "outputId": "b7f47d32-6177-4715-957c-399a72f2b7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Evaluation Metrics (on valid responses):\n",
            "ğŸ§® Accuracy : 0.8360\n",
            "âœ… Precision: 0.7530\n",
            "ğŸ” Recall   : 1.0000\n",
            "â­ F1 Score : 0.8591\n",
            "\n",
            "ğŸ“¦ Valid Predictions: 2000 / 2000 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.5 ğŸ Results Summary â€“ `UTwente` Dataset\n",
        "\n",
        "#### âœ… Evaluation Metrics (on 2,000 valid outputs):\n",
        "- **Accuracy**: `83.6%`  \n",
        "- **Precision**: `75.3%`  \n",
        "- **Recall**: `100.0%`  \n",
        "- **F1 Score**: `85.9%`  \n",
        "- **Total Processed Emails**: `2,000`  \n",
        "- **Valid JSON Responses**: `100%`\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  Interpretation:\n",
        "\n",
        "The model showed exceptional **recall**, detecting all phishing attempts with zero false negatives. While a few legitimate emails were incorrectly flagged as phishing (lowering precision), this behavior aligns well with real-world SOC needs, where itâ€™s safer to over-alert than to miss a threat.\n",
        "\n",
        "These results indicate that the model is highly effective at catching phishing threats, though further tuning or rule-based filtering might be helpful to reduce false positives in production settings.\n"
      ],
      "metadata": {
        "id": "miEWYXc6SpCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 ğŸ—‚ï¸ Dataset: `Ahmad Tijjani Kaggle` (Phishing Detection with Category Context)\n",
        "\n",
        "This dataset contains labeled phishing emails enriched with contextual **categories** describing the attack style or psychological tactic. It is ideal for evaluating LLMs on their ability to detect phishing attempts and understand the underlying method of deception.\n",
        "\n",
        "Each entry includes:\n",
        "- `text`: the full email content (subject + body)\n",
        "- `label`: phishing classification (`phishing` or `safe`)\n",
        "- `category`: the thematic phishing type (e.g., â€œurgencyâ€, â€œauthorityâ€)\n",
        "\n",
        "Once uploaded, we will:\n",
        "- âœ… Convert textual labels to binary (`1` = phishing, `0` = safe)\n",
        "- âœ… Preview dataset structure and basic stats\n",
        "- âœ… Visualize the distribution of phishing categories\n",
        "- âœ… Generate prompts for structured zero-shot inference\n",
        "\n",
        "> ğŸ§  This evaluation uses **zero-shot prompt-based inference only**, with no fine-tuning.\n"
      ],
      "metadata": {
        "id": "rw1VR832M-jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 ğŸ—‚ï¸ Upload and Load the `Ahmad Tijjani Kaggle` Dataset\n",
        "\n",
        "In this step, we upload the phishing dataset for zero-shot benchmarking. Each sample includes:\n",
        "- The email content under the `text` column\n",
        "- A phishing label under the `label` column (`phishing` or `safe`)\n",
        "- A `category` column representing the type of phishing tactic (e.g., urgency, authority)\n",
        "\n",
        "Once uploaded, we will:\n",
        "- Load the dataset into memory using Pandas\n",
        "- Display the number of rows and column names\n",
        "- Preview a few sample entries to confirm structure and readiness for preprocessing\n"
      ],
      "metadata": {
        "id": "k4aAMlEnNAx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§  Section 2.2.1 â€“ Upload and Load the Ahmad Tijjani Kaggle Dataset\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# ğŸ“¤ Upload dataset\n",
        "print(\"ğŸ“¤ Please upload the 'phishing_dataset_with_category.csv' file.\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# âœ… Load dataset\n",
        "df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "print(f\"\\nâœ… Dataset loaded: {file_name}\")\n",
        "print(f\"ğŸ“¦ Rows: {len(df)}\")\n",
        "print(f\"ğŸ§¾ Columns: {df.columns.tolist()}\")\n",
        "\n",
        "# âœ… Preview first few rows\n",
        "display(df.head())\n",
        "\n",
        "# âœ… Show label distribution\n",
        "label_counts = df[\"label\"].value_counts()\n",
        "print(\"\\nğŸ” Label Distribution:\")\n",
        "print(label_counts)\n",
        "\n",
        "# âœ… Show phishing category breakdown\n",
        "category_counts = df[\"category\"].value_counts()\n",
        "print(\"\\nğŸ“‚ Category Breakdown:\")\n",
        "print(category_counts)\n",
        "\n",
        "# âœ… Show a sample phishing email\n",
        "print(\"\\nğŸ“Œ Sample Phishing Email:\")\n",
        "sample = df[df[\"label\"] == \"phishing\"].sample(1, random_state=42)\n",
        "print(sample[[\"text\", \"category\"]].to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "7zai7BiPNAMs",
        "outputId": "c8827f05-51a4-4a06-ad7b-0588b7bc3f26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¤ Please upload the 'phishing_dataset_with_category.csv' file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-563e6f97-a5a2-4d2b-be9e-a825e25b9ff0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-563e6f97-a5a2-4d2b-be9e-a825e25b9ff0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving phishing_dataset_with_category.csv to phishing_dataset_with_category (1).csv\n",
            "\n",
            "âœ… Dataset loaded: phishing_dataset_with_category (1).csv\n",
            "ğŸ“¦ Rows: 1000\n",
            "ğŸ§¾ Columns: ['text', 'category', 'label']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                text   category     label\n",
              "0  Warning: Unusual login attempt detected on you...    urgency  phishing\n",
              "1  Urgent! Your Google has been compromised. Clic...    urgency  phishing\n",
              "2  This is an official notice from Amazon. Your a...  authority  phishing\n",
              "3  As per HMRC regulations, you must update your ...  authority  phishing\n",
              "4  Immediate action required: Your Spotify subscr...    urgency  phishing"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b3844c3-dfc4-4fa2-8495-03f44fc5c49b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Warning: Unusual login attempt detected on you...</td>\n",
              "      <td>urgency</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Urgent! Your Google has been compromised. Clic...</td>\n",
              "      <td>urgency</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is an official notice from Amazon. Your a...</td>\n",
              "      <td>authority</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As per HMRC regulations, you must update your ...</td>\n",
              "      <td>authority</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Immediate action required: Your Spotify subscr...</td>\n",
              "      <td>urgency</td>\n",
              "      <td>phishing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b3844c3-dfc4-4fa2-8495-03f44fc5c49b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b3844c3-dfc4-4fa2-8495-03f44fc5c49b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b3844c3-dfc4-4fa2-8495-03f44fc5c49b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7c96bb1e-180d-4300-b152-859326e3396f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c96bb1e-180d-4300-b152-859326e3396f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7c96bb1e-180d-4300-b152-859326e3396f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(sample[[\\\"text\\\", \\\"category\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Urgent! Your Google has been compromised. Click here to secure it now!\",\n          \"Immediate action required: Your Spotify subscription is expiring. Renew now.\",\n          \"This is an official notice from Amazon. Your account requires immediate verification.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"authority\",\n          \"urgency\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"phishing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” Label Distribution:\n",
            "label\n",
            "phishing    1000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ğŸ“‚ Category Breakdown:\n",
            "category\n",
            "authority     350\n",
            "persuasion    328\n",
            "urgency       322\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ğŸ“Œ Sample Phishing Email:\n",
            "                                                                         text category\n",
            "Warning: Unusual login attempt detected on your Amazon. Verify your identity.  urgency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 ğŸ§  Preprocess Dataset and Generate Structured Prompts\n",
        "\n",
        "In this step, we prepare the dataset for prompt-based inference.\n",
        "\n",
        "Steps include:\n",
        "- Converting the `label` column to binary format:\n",
        "  - `phishing` â†’ `1`\n",
        "  - `safe` â†’ `0`\n",
        "- Generating a structured **instruction prompt** for each email\n",
        "- Appending the prompt as a new column for inference use\n",
        "\n",
        "Each prompt instructs the model to act as a cybersecurity expert and respond in a strict JSON format, enabling structured output extraction and evaluation.\n"
      ],
      "metadata": {
        "id": "jLy9LqPdNYa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§  Section 2.2.2 â€“ Preprocess Dataset and Generate Structured Prompts\n",
        "\n",
        "# âœ… Convert labels to binary\n",
        "df[\"label\"] = df[\"label\"].map({\"phishing\": 1, \"safe\": 0})\n",
        "\n",
        "# âœ… Define prompt template\n",
        "def build_prompt(email_body):\n",
        "    return f\"\"\"### Instruction:\n",
        "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
        "\n",
        "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
        "\n",
        "- A link to a document/file from an unfamiliar or suspicious domain (e.g. fake Google Drive, Dropbox, corpfiles.net instead of corpfile.com)\n",
        "- Urgent language or pressure to act quickly\n",
        "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
        "- Requests to click, download, or input sensitive data\n",
        "- Email sender addresses mimicking known brands or internal departments\n",
        "- Unexpected attachments or shared documents\n",
        "- Impersonation of executives, HR, IT, or Finance\n",
        "- Spelling mistakes or inconsistencies in formatting\n",
        "\n",
        "### Respond in **this exact JSON format**:\n",
        "{{\n",
        "  \"Is_Phishing\": boolean,\n",
        "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
        "  \"Suspicious_Links\": [\"...\"],\n",
        "  \"Social_Engineering_Elements\": [\"...\"],\n",
        "  \"Actions\": [\"...\"],\n",
        "  \"Reason\": \"...\"\n",
        "}}\n",
        "\n",
        "### Email:\n",
        "{email_body}\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "# âœ… Generate prompt column\n",
        "df[\"prompt\"] = df[\"text\"].apply(build_prompt)\n",
        "\n",
        "# âœ… Preview one phishing prompt\n",
        "sample_index = df[df[\"label\"] == 1].sample(1, random_state=42).index[0]\n",
        "print(\"\\nğŸ“Œ Full Prompt Example (Phishing Email):\\n\")\n",
        "print(df.loc[sample_index, \"prompt\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWNQnbfUNZnh",
        "outputId": "e52066a5-8001-4c03-decb-ea93226571e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Œ Full Prompt Example (Phishing Email):\n",
            "\n",
            "### Instruction:\n",
            "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
            "\n",
            "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
            "\n",
            "- A link to a document/file from an unfamiliar or suspicious domain (e.g. fake Google Drive, Dropbox, corpfiles.net instead of corpfile.com)\n",
            "- Urgent language or pressure to act quickly\n",
            "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
            "- Requests to click, download, or input sensitive data\n",
            "- Email sender addresses mimicking known brands or internal departments\n",
            "- Unexpected attachments or shared documents\n",
            "- Impersonation of executives, HR, IT, or Finance\n",
            "- Spelling mistakes or inconsistencies in formatting\n",
            "\n",
            "### Respond in **this exact JSON format**:\n",
            "{\n",
            "  \"Is_Phishing\": boolean,\n",
            "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
            "  \"Suspicious_Links\": [\"...\"],\n",
            "  \"Social_Engineering_Elements\": [\"...\"],\n",
            "  \"Actions\": [\"...\"],\n",
            "  \"Reason\": \"...\"\n",
            "}\n",
            "\n",
            "### Email:\n",
            "Warning: Unusual login attempt detected on your Amazon. Verify your identity.\n",
            "\n",
            "### Response:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3 ğŸ¤– Run Batched Inference and Extract Structured JSON Output\n",
        "\n",
        "In this step, we perform **batched inference** on the structured prompts using the loaded LLM (e.g., Mistral-7B).\n",
        "\n",
        "Steps include:\n",
        "- Tokenizing prompts with appropriate padding and truncation\n",
        "- Generating responses using `inference_mode()` for speed and memory efficiency\n",
        "- Extracting the modelâ€™s JSON output block using regular expressions\n",
        "- Parsing each output into Python dictionaries for evaluation\n",
        "\n",
        "The parsed JSON is stored under a new `model_output` column in the DataFrame for further analysis.\n"
      ],
      "metadata": {
        "id": "UFe-bvKvNqw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import inference_mode\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import json\n",
        "\n",
        "# ğŸ”§ Inference configuration\n",
        "batch_size = 16\n",
        "max_prompt_length = 1024\n",
        "all_predictions = []\n",
        "\n",
        "print(f\"ğŸ” Running batched inference (batch size = {batch_size})...\")\n",
        "\n",
        "# ğŸ”„ Batched generation loop\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    batch_prompts = df[\"prompt\"].iloc[i:i+batch_size].tolist()\n",
        "\n",
        "    # Tokenize input prompts\n",
        "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_prompt_length).to(\"cuda\")\n",
        "\n",
        "    with inference_mode():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=384,\n",
        "            temperature=0.0,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode and extract JSON\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    for decoded in decoded_outputs:\n",
        "        matches = list(re.finditer(r\"\\{[\\s\\S]+?\\}\", decoded))\n",
        "        json_text = matches[-1].group() if matches else \"\"\n",
        "        try:\n",
        "            parsed = json.loads(json_text) if json_text else {\"error\": \"no_json_found\", \"raw\": decoded}\n",
        "        except:\n",
        "            parsed = {\"error\": \"invalid_json\", \"raw\": decoded}\n",
        "        all_predictions.append(parsed)\n",
        "\n",
        "# âœ… Store model outputs\n",
        "df[\"model_output\"] = all_predictions\n",
        "print(\"âœ… Batched inference complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hd24Vn5NrPw",
        "outputId": "8dcf2d12-1627-4a3a-ca8a-eaa82789c7b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Running batched inference (batch size = 16)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [11:00<00:00, 10.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Batched inference complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.4 ğŸ“Š Inference Results Summary and Evaluation\n",
        "\n",
        "After running zero-shot inference on the `Ahmad Tijjani Kaggle` dataset, the model produced structured JSON outputs for all entries.\n",
        "\n",
        "In this step, we:\n",
        "- Extract the predicted `Is_Phishing` value from each JSON response\n",
        "- Filter out invalid or unparseable results\n",
        "- Compare predictions against ground truth labels\n",
        "- Calculate evaluation metrics including:\n",
        "  - Accuracy\n",
        "  - Precision\n",
        "  - Recall\n",
        "  - F1 Score\n",
        "\n",
        "This provides a performance snapshot of the model's phishing detection capabilities based solely on prompt engineering.\n",
        "\n",
        "> ğŸ“Œ These metrics help assess practical utility in real-world SOC automation pipelines.\n"
      ],
      "metadata": {
        "id": "7kp_v40EN0-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# âœ… Extract binary predictions\n",
        "def extract_prediction(obj):\n",
        "    if isinstance(obj, dict) and \"Is_Phishing\" in obj:\n",
        "        return int(obj[\"Is_Phishing\"]) if isinstance(obj[\"Is_Phishing\"], bool) else None\n",
        "    return None\n",
        "\n",
        "df[\"predicted_label\"] = df[\"model_output\"].apply(extract_prediction)\n",
        "\n",
        "# âœ… Filter valid rows\n",
        "valid = df.dropna(subset=[\"predicted_label\"])\n",
        "y_true = valid[\"label\"]\n",
        "y_pred = valid[\"predicted_label\"]\n",
        "\n",
        "# âœ… Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# ğŸ“Š Display results\n",
        "print(\"ğŸ“Š Evaluation Metrics (on valid responses):\")\n",
        "print(f\"ğŸ§® Accuracy : {accuracy:.4f}\")\n",
        "print(f\"âœ… Precision: {precision:.4f}\")\n",
        "print(f\"ğŸ” Recall   : {recall:.4f}\")\n",
        "print(f\"â­ F1 Score : {f1:.4f}\")\n",
        "print(f\"\\nğŸ“¦ Valid Predictions: {len(valid)} / {len(df)} total\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKrt0_NLN1-I",
        "outputId": "d2370482-0372-40d5-923c-50f922c07a32"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Evaluation Metrics (on valid responses):\n",
            "ğŸ§® Accuracy : 1.0000\n",
            "âœ… Precision: 1.0000\n",
            "ğŸ” Recall   : 1.0000\n",
            "â­ F1 Score : 1.0000\n",
            "\n",
            "ğŸ“¦ Valid Predictions: 1000 / 1000 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.5 ğŸ Results Summary â€“ `Ahmad Tijjani Kaggle` Dataset\n",
        "\n",
        "After completing inference and evaluation, the model demonstrated **perfect performance** on the `Ahmad Tijjani Kaggle` dataset.\n",
        "\n",
        "### âœ… Final Evaluation Metrics:\n",
        "- **Accuracy**: 100.0%\n",
        "- **Precision**: 100.0%\n",
        "- **Recall**: 100.0%\n",
        "- **F1 Score**: 100.0%\n",
        "- **Valid Outputs**: 1000 / 1000 structured responses parsed successfully\n",
        "\n",
        "### ğŸ§  Interpretation:\n",
        "- The model correctly identified all phishing and legitimate emails with no false positives or false negatives.\n",
        "- Structured output formatting was followed strictly, enabling reliable parsing.\n",
        "- These results are ideal for automation in high-risk environments such as Security Operations Centers (SOC).\n",
        "\n",
        "> ğŸ“Œ Note: These results are dataset-specific. Additional datasets should be tested to validate generalizability and uncover potential blind spots.\n"
      ],
      "metadata": {
        "id": "jxh37gRISUsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 ğŸ—‚ï¸ Dataset: `Charlotte Hall` (Classified by Attack Strategy)\n",
        "\n",
        "This dataset contains phishing and legitimate emails, organized by **type of phishing attack**, such as traditional and spear-phishing.\n",
        "\n",
        "Each entry includes:\n",
        "- `Email`: the full message content (subject + body)\n",
        "- `Type`: the type of email, indicating its phishing subtype\n",
        "- `Label`: classification as phishing or legitimate\n",
        "\n",
        "Once loaded, we will:\n",
        "- âœ… Inspect column names and row count\n",
        "- âœ… Standardize the structure\n",
        "- âœ… Preview email content\n",
        "- âœ… Count phishing vs. safe samples\n",
        "- âœ… Analyze the distribution of phishing types\n",
        "\n",
        "> ğŸ§  This dataset supports evaluating model performance on multiple phishing styles, not just binary classification.\n"
      ],
      "metadata": {
        "id": "v3Htb7kGaVgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.1 ğŸ—‚ï¸ Upload and Load the `Phishing Email Data by Type` Dataset\n",
        "\n",
        "In this step, we upload and inspect a dataset that contains phishing and legitimate emails labeled by type (e.g., traditional phishing, spear phishing, etc.).\n",
        "\n",
        "The dataset includes:\n",
        "- `Email`: the raw email content (subject + body)\n",
        "- `Type`: the category of phishing attack (e.g., \"Invoice Scam\", \"Credential Theft\")\n",
        "- `Label`: whether the email is a phishing attempt (`phishing`) or not (`legitimate` or `safe`)\n",
        "\n",
        "Once uploaded, we will:\n",
        "- Load the dataset using Pandas\n",
        "- Check the total number of rows and column names\n",
        "- Preview the first few rows to confirm the structure before preprocessing\n"
      ],
      "metadata": {
        "id": "xvFhy40zcYEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§  Section 2.3.1 â€“ Upload and Load the Phishing Email Data by Type Dataset\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# ğŸ“¤ Upload dataset\n",
        "print(\"ğŸ“¤ Please upload the 'phishing_data_by_type.csv' file.\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# âœ… Load dataset\n",
        "df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "print(f\"\\nâœ… Dataset loaded: {file_name}\")\n",
        "print(f\"ğŸ“¦ Rows: {len(df)}\")\n",
        "print(f\"ğŸ§¾ Columns: {df.columns.tolist()}\")\n",
        "\n",
        "# âœ… Preview first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "zzls5mvkaXfu",
        "outputId": "0623c5bd-a95d-442c-c3e5-e4f70028b80c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¤ Please upload the 'phishing_data_by_type.csv' file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d00cdeaf-b6d5-4e0a-a9c5-0cbf3c640cf1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d00cdeaf-b6d5-4e0a-a9c5-0cbf3c640cf1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving phishing_data_by_type.csv to phishing_data_by_type.csv\n",
            "\n",
            "âœ… Dataset loaded: phishing_data_by_type.csv\n",
            "ğŸ“¦ Rows: 159\n",
            "ğŸ§¾ Columns: ['Subject', 'Text', 'Type']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      Subject  \\\n",
              "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP   \n",
              "1         URGENT ASSISTANCE /RELATIONSHIP (P)   \n",
              "2                             GOOD DAY TO YOU   \n",
              "3                            from Mrs.Johnson   \n",
              "4                                Co-Operation   \n",
              "\n",
              "                                                Text   Type  \n",
              "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...  Fraud  \n",
              "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...  Fraud  \n",
              "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...  Fraud  \n",
              "3  Goodday Dear\\n\\n\\nI know this mail will come t...  Fraud  \n",
              "4  FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...  Fraud  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b8624a1-4bf1-49e1-bd91-1e84e8979db1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject</th>\n",
              "      <th>Text</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
              "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
              "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GOOD DAY TO YOU</td>\n",
              "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>from Mrs.Johnson</td>\n",
              "      <td>Goodday Dear\\n\\n\\nI know this mail will come t...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Co-Operation</td>\n",
              "      <td>FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b8624a1-4bf1-49e1-bd91-1e84e8979db1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b8624a1-4bf1-49e1-bd91-1e84e8979db1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b8624a1-4bf1-49e1-bd91-1e84e8979db1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9eb3b018-9ea6-469d-a9bb-b515274b0e78\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9eb3b018-9ea6-469d-a9bb-b515274b0e78')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9eb3b018-9ea6-469d-a9bb-b515274b0e78 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 159,\n  \"fields\": [\n    {\n      \"column\": \"Subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 157,\n        \"samples\": [\n          \"Hooray we've announced Opening Day!\\r\",\n          \"Due security reasons we may have to close your bank account.\",\n          \"Breaking News: Jan. 6 investigators have found gaps in White House phone records during the Capitol riot, when they know Donald Trump was making calls\\r\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 159,\n        \"samples\": [\n          \"Hello!\\r\\n\\r\\nMy name is Shafaq.\\r\\n\\r\\nYour website or a website that your company hosts is infringing on a\\r\\ncopyright-protected images owned by myself.\\r\\n\\r\\nTake a look at this document with the links to my images you used at\\r\\nwebsite.berkeley.edu and my earlier publications to get the evidence of\\r\\nmy copyrights.\\r\\n\\r\\nDownload it right now and check this out for yourself:\\r\\n\\r\\n\\r\\nhxxps://sites.google.com/view/a0hf49gj29g-i4jb48n5/drive/folders/shared/1/download?ID=308682351554855915\\r\\n\\r\\nI believe you have willfully infringed my rights under 17 U.S.C. Section\\r\\n101 et seq. and could be liable for statutory damages as high as\\r\\n$150,000 as set forth in Section 504(c)(2) of the Digital Millennium\\r\\nCopyright Act (\\u201dDMCA\\u201d) therein.\\r\\n\\r\\nThis letter is official notification. I seek the removal of the\\r\\ninfringing material referenced above. Please take note as a service\\r\\nprovider, the Digital Millennium Copyright Act requires you, to remove\\r\\nor disable access to the infringing materials upon receipt of this\\r\\nnotice. If you do not cease the use of the aforementioned copyrighted\\r\\nmaterial a lawsuit will be commenced against you.\\r\\n\\r\\nI have a good faith belief that use of the copyrighted materials\\r\\ndescribed above as allegedly infringing is not authorized by the\\r\\ncopyright owner, its agent, or the law.\\r\\n\\r\\nI swear, under penalty of perjury, that the information in the\\r\\nnotification is accurate and that I am the copyright owner or am\\r\\nauthorized to act on behalf of the owner of an exclusive right that is\\r\\nallegedly infringed.\\r\\n\\r\\n\\r\\nBest regards,\\r\\nShafaq Chyanne\",\n          \"INAUGURAL BROADWAY PERFORMANCE APRIL 14\\r\\nA NEW COMEDY From Five-Time Tony Award\\u00ae-Winning Director SUSAN STROMAN and introducing playwright SELINA FILLINGER\\r\\nLILLI COOPER  LEA DELARIA  RACHEL DRATCH  JULIANNE HOUGH  SUZY NAKAMURA  JULIE WHITE  VANESSA WILLIAMS\\r\\nPOTUS or, behind every great dumb@ss are seven women trying to keep him alive\\r\\nBE THE FIRST TO WITNESS THE GROUNDBREAKING NEW COMEDY COMING THIS SPRING\\r\\n\\tGET TICKETS\\t\\r\\nOne 4-letter word is about to rock 1600 Pennsylvania Avenue. When the President unwittingly spins a PR nightmare into a global crisis, the seven brilliant and beleaguered women he relies upon most will risk life, liberty, and the pursuit of sanity to keep the Commander in Chief out of trouble.\\r\\nA MESSAGE FROM THE CAST\\r\\nA message from the cast\\r\\n\\r\\n    \\r\\n \\r\\nYou received this message because you subscribed to our emails or you made a purchase from\\r\\nBroadway.com. Manage my preferences\",\n          \"Worlds of Fun\\nManage My Email Preferences\\nWorlds of Fun - Connections Newsletter\\nHere's Your February 17 Park News:\\n\\nOpening Day is April 30!\\nWorlds of Fun welcomes guests back on April 30 for Opening Day of the 2022 season. Get ready for another year of FUN with the park's lineup  of world-class attractions as well as unforgettable family fun with the PEANUTS\\u2122 gang in Planet Snoopy.\\n\\nA 2022 Gold Pass gets you unlimited visits to the park and Oceans of Fun waterpark all season long PLUS free parking, exclusive discounts and more! Purchase your Gold Pass for just 5 easy payments of $15*.\\n\\n*Initial payment required. Plus applicable fees.\\nLEARN MORE\\n-\\n\\nLive Entertainment Summer Season Casting!\\nAre you ready to shine? Worlds of Fun is casting for singers, dancers, musicians, and Character Performers & Midway Actors for the 2022 Summer Season. For an audition form and more information, email: auditions@worldsoffun.com.\\nLEARN MORE\\n-\\n\\nLooking for that perfect summer job?\\nWorlds of Fun is hiring! We are looking for team members to join our 2022 season. A diverse range of job opportunities are available, and associates are needed in all areas of park operations.  Must be 16 years of age to apply.\\nLEARN MORE\\n-\\n\\nFree Fun for Our Littlest Guests!\\nThe Pre-K Pass is FREE for kids ages 3-5 years old and gets you unlimited visits for 2022, including Oceans of Fun waterpark! With a Pre-K Pass, our littlest guests can come and go as often as they'd like - for FREE!\\n\\nLEARN MORE\\n-\\nFOLLOW US:\\nFacebook        Twitter        Instagram\\nUnsubscribe Now\\n\\nSUBSCRIPTION INFORMATION: This message was sent to as a result of your election to receive email from Worlds of Fun.\\nVisit our online profile center where you can manage your profile, control your list preferences, or unsubscribe from all e-mail from Cedar Fair Entertainment Company.\\nADMINISTRATIVE INFORMATION: This e-mail is published by Worlds of Fun, 4545 Worlds of Fun Ave., Kansas City, MO 64161. Worlds of Fun is a brand of Cedar Fair Entertainment Company.\\n\\u00a9 2022 CEDAR FAIR ENTERTAINMENT COMPANY\\n\\u00a9 2022 PEANUTS WORLDWIDE LLC\\nPRIVACY POLICY: We respect your right to privacy. This Worlds of Fun publication is subject to the Cedar Fair Entertainment Company online  privacy policy.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Phishing\",\n          \"Commercial Spam\",\n          \"Fraud\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.2 ğŸ§  Preprocess Dataset and Generate Structured Prompts\n",
        "\n",
        "In this step, we prepare the `Phishing Email Data by Type` dataset for prompt-based inference by:\n",
        "\n",
        "- Merging the `Subject` and `Text` columns into a single `text` field\n",
        "- Renaming `Type` to `category` for clarity\n",
        "- Mapping the following categories to binary labels:\n",
        "  - `Phishing`, `Fraud`, `Commercial Spam` â†’ `1` (phishing/malicious)\n",
        "  - `False Positives` â†’ `0` (safe)\n",
        "- Generating a structured **LLM prompt** for each email based on the combined subject and body\n",
        "- Storing the generated prompt in a new `prompt` column for batch inference\n",
        "\n",
        "This configuration reflects a strict security posture: **even commercial spam is treated as phishing**, as it may contain risky links or deceptive elements that can compromise employee safety.\n"
      ],
      "metadata": {
        "id": "0KfIrBCI_Wem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§  Section 2.3.2 â€“ Preprocess and Generate Structured Prompts (Adjusted for phishing_data_by_type.csv)\n",
        "\n",
        "# âœ… Combine subject + body into a unified 'text' column\n",
        "df[\"text\"] = \"SUBJECT: \" + df[\"Subject\"].fillna(\"\") + \"\\n\\n\" + df[\"Text\"].fillna(\"\")\n",
        "\n",
        "# âœ… Rename the phishing type column\n",
        "df = df.rename(columns={\"Type\": \"category\"})\n",
        "\n",
        "# âœ… Map 'category' to binary phishing labels\n",
        "# We'll treat only 'Phishing' and 'Fraud' as phishing, others as safe\n",
        "phishing_labels = {\"Phishing\": 1, \"Fraud\": 1, \"False Positives\": 0, \"Commercial Spam\": 0}\n",
        "df[\"label\"] = df[\"category\"].map(phishing_labels)\n",
        "\n",
        "# âœ… Prompt generation function (kept unchanged)\n",
        "def build_prompt(email_body):\n",
        "    return f\"\"\"### Instruction:\n",
        "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
        "\n",
        "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
        "\n",
        "- A link to a document/file from an unfamiliar or suspicious domain\n",
        "- Urgent language or pressure to act quickly\n",
        "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
        "- Requests to click, download, or input sensitive data\n",
        "- Email sender addresses mimicking known brands or internal departments\n",
        "- Unexpected attachments or shared documents\n",
        "- Impersonation of executives, HR, IT, or Finance\n",
        "- Spelling mistakes or inconsistencies in formatting\n",
        "\n",
        "### Respond in **this exact JSON format**:\n",
        "{{\n",
        "  \"Is_Phishing\": boolean,\n",
        "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
        "  \"Suspicious_Links\": [\"...\"],\n",
        "  \"Social_Engineering_Elements\": [\"...\"],\n",
        "  \"Actions\": [\"...\"],\n",
        "  \"Reason\": \"...\"\n",
        "}}\n",
        "\n",
        "### Email:\n",
        "{email_body}\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "# âœ… Generate prompts\n",
        "df[\"prompt\"] = df[\"text\"].apply(build_prompt)\n",
        "\n",
        "# âœ… Preview a prompt from a real phishing email\n",
        "sample_index = df[df[\"label\"] == 1].sample(1, random_state=42).index[0]\n",
        "print(\"\\nğŸ“Œ Full Prompt Example (Phishing Email):\\n\")\n",
        "print(df.loc[sample_index, \"prompt\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSevsYk9_nsn",
        "outputId": "cce62c40-7bdf-47b1-9b88-b62d00317c92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Œ Full Prompt Example (Phishing Email):\n",
            "\n",
            "### Instruction:\n",
            "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
            "\n",
            "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
            "\n",
            "- A link to a document/file from an unfamiliar or suspicious domain\n",
            "- Urgent language or pressure to act quickly\n",
            "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
            "- Requests to click, download, or input sensitive data\n",
            "- Email sender addresses mimicking known brands or internal departments\n",
            "- Unexpected attachments or shared documents\n",
            "- Impersonation of executives, HR, IT, or Finance\n",
            "- Spelling mistakes or inconsistencies in formatting\n",
            "\n",
            "### Respond in **this exact JSON format**:\n",
            "{\n",
            "  \"Is_Phishing\": boolean,\n",
            "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
            "  \"Suspicious_Links\": [\"...\"],\n",
            "  \"Social_Engineering_Elements\": [\"...\"],\n",
            "  \"Actions\": [\"...\"],\n",
            "  \"Reason\": \"...\"\n",
            "}\n",
            "\n",
            "### Email:\n",
            "SUBJECT: From: Mr.Al-Zarqawi Yusuf \n",
            "\n",
            "Dear Friend,\n",
            "\n",
            "Your first reaction to this mail will be total rejection, scare and maybe\n",
            "disbelief, owning largely to the atrocities people commit these days.But\n",
            "this mail comes from a devastated, sorrowful and emotional laden soul that\n",
            "needs compassion from a kind and good spirited person to wipe away my\n",
            "tears and appropriate my dream and humanitarian gesture.\n",
            "\n",
            "As you read this, I don't want you to  feel sorry for me, because, I\n",
            "believe everyone dies someday.,I am Al-Zarqawi Yusuf, A Oil merchant in\n",
            "Dubai, United Arab Emirate ( UAE). I have been diagnosed with Cancer,\n",
            "which was discovered very late, due to my laxity in caring for my health.\n",
            "It has defiled all forms of medicine; Right now I have only about a\n",
            "limited to live, according to my Medical Doctor. I have not particularly\n",
            "lived my life so well, as I never really cared for myself but the Oil\n",
            "business.Though I am very rich, I was never generous, I only focused on my\n",
            "business as that was the only thing I cared for. But now I regret all this\n",
            "as I now know that there is more to life than just wanting to have or make\n",
            "all the money in the world.\n",
            "\n",
            "I believe when Allah  gives me a second chance and  heal me I would live\n",
            "my life a different way from how I have lived it.I have sowed a seed for\n",
            "my healing I have willed and given most of my properties and assets to my\n",
            "immediate and extended family members and as well as a few close friends.\n",
            "i want Allah to be merciful to me and accept my soul and so, I have\n",
            "decided to give arms to charity organizations and give succor and comfort\n",
            "to the less privileged of the Tsunami and Hurricane Katrina Victims, as I\n",
            "want this to be one of the last good deeds I do on earth so far, by\n",
            "distributed some of this money to some charity organizations in\n",
            "India,Hurricane Katrina victims in USA and other part of the world. Now\n",
            "that my health has deteriorated so badly, I cannot do this my self\n",
            "anymore.I once asked members of my family  to close one of my accounts in\n",
            "Saudi Bank and distribute the money which I have there to charity\n",
            "organization and to the less  privileged in Bulgaria and Sudan.  They\n",
            "cashed the money but kept it only to themselves.\n",
            "\n",
            "Hence I do not trust them anymore,as they seem not to be contended with\n",
            "what I have left for them already.The last of my money, which no one knows\n",
            "of, is the huge cash deposit of Thirty Five Million United States Dollars\n",
            "( US$35Million)  that I have in the Vault of The Security Company as\n",
            "family valuable since the year 2003 for safekeeping.I want you to collect\n",
            "this deposit on my behalf and disburse it to the Tsunami Earthquake\n",
            "victims in Asia for the less privileged. Please send me a mail to indicate\n",
            "your wiliness to assist in this disbursement.\n",
            "\n",
            " I will set aside 10% for you for your time and efforts by notifying the\n",
            "security company as soon as i hear from you.I need your urgent reply with\n",
            "your full name and address, your Phone and Fax numbers and your\n",
            "Occupation so that I will not have to go on sourcing for a credible\n",
            "person to handle this project for himself and the rest of the less\n",
            "privileged.I will also plead to you to always pray for me because only\n",
            "Allah heals.\n",
            "\n",
            "\n",
            "Wasaalam\n",
            "\n",
            "Regards,\n",
            "Al-Zarqawi Yusuf.\n",
            "\n",
            "### Response:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.3 ğŸ¤– Run Batched Inference and Extract Structured JSON Output\n",
        "\n",
        "In this step, we use a large language model (e.g., Mistral, LLaMA) to process the structured prompts in batches.\n",
        "\n",
        "Steps include:\n",
        "- Tokenizing each prompt with padding and truncation\n",
        "- Running the model in inference-only mode for efficiency\n",
        "- Decoding the modelâ€™s raw response\n",
        "- Extracting and parsing the **structured JSON output**\n",
        "- Appending each prediction to the dataset for downstream evaluation\n",
        "\n",
        "The output is stored in a new column called `model_output`.\n"
      ],
      "metadata": {
        "id": "8ChK86-mclz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import inference_mode\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import json\n",
        "\n",
        "# ğŸ”§ Inference config\n",
        "# Inference configuration\n",
        "batch_size = 16\n",
        "max_prompt_length = 2048\n",
        "\n",
        "print(f\"ğŸ” Running batched inference (batch size = {batch_size})...\")\n",
        "\n",
        "# ğŸ”„ Batched inference loop\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    batch_prompts = df[\"prompt\"].iloc[i:i+batch_size].tolist()\n",
        "\n",
        "    # Tokenize inputs\n",
        "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_prompt_length).to(\"cuda\")\n",
        "\n",
        "    with inference_mode():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=2048,\n",
        "            temperature=0.0,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode and extract structured JSON\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    for decoded in decoded_outputs:\n",
        "        matches = list(re.finditer(r\"\\{[\\s\\S]+?\\}\", decoded))\n",
        "        json_text = matches[-1].group() if matches else \"\"\n",
        "        try:\n",
        "            parsed = json.loads(json_text) if json_text else {\"error\": \"no_json_found\", \"raw\": decoded}\n",
        "        except:\n",
        "            parsed = {\"error\": \"invalid_json\", \"raw\": decoded}\n",
        "        all_predictions.append(parsed)\n",
        "\n",
        "# âœ… Store model outputs\n",
        "df[\"model_output\"] = all_predictions\n",
        "print(\"âœ… Batched inference complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29JSo2F3cw3G",
        "outputId": "34f34757-84e9-4da7-99b7-a9ca617bf792"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Running batched inference (batch size = 16)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [18:24<00:00, 110.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Batched inference complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.4 ğŸ“Š Inference Results Summary and Evaluation\n",
        "\n",
        "After running structured inference on the `Phishing Email Data by Type` dataset, we now evaluate the modelâ€™s predictions against the true labels.\n",
        "\n",
        "In this step, we:\n",
        "- Extract the `\"Is_Phishing\"` prediction from the modelâ€™s JSON output\n",
        "- Compare the modelâ€™s output with ground truth binary labels\n",
        "- Compute key classification metrics:\n",
        "  - Accuracy\n",
        "  - Precision\n",
        "  - Recall\n",
        "  - F1 Score\n",
        "- Identify how well the model handles various phishing types, commercial spam, and false positives\n",
        "\n",
        "> ğŸ“Œ These metrics help assess whether the model is too aggressive (many false positives) or too permissive (missed phishing threats).\n"
      ],
      "metadata": {
        "id": "4kaWlN6q-_UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# âœ… Extract model-predicted labels from the structured JSON\n",
        "def extract_prediction(obj):\n",
        "    if isinstance(obj, dict) and \"Is_Phishing\" in obj:\n",
        "        return int(obj[\"Is_Phishing\"]) if isinstance(obj[\"Is_Phishing\"], bool) else None\n",
        "    return None\n",
        "\n",
        "df[\"predicted_label\"] = df[\"model_output\"].apply(extract_prediction)\n",
        "\n",
        "# âœ… Filter only valid predictions\n",
        "valid = df.dropna(subset=[\"label\", \"predicted_label\"])\n",
        "y_true = valid[\"label\"]\n",
        "y_pred = valid[\"predicted_label\"]\n",
        "\n",
        "# âœ… Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# âœ… Summary\n",
        "print(\"ğŸ“Š Evaluation Metrics (on valid responses):\")\n",
        "print(f\"ğŸ§® Accuracy : {accuracy:.4f}\")\n",
        "print(f\"âœ… Precision: {precision:.4f}\")\n",
        "print(f\"ğŸ” Recall   : {recall:.4f}\")\n",
        "print(f\"â­ F1 Score : {f1:.4f}\")\n",
        "print(f\"\\nğŸ“¦ Valid Predictions: {len(valid)} / {len(df)} total\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2u_dY6K_BXb",
        "outputId": "a3ac9ebc-4ca8-4602-d3d0-fbe9b99c08fd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Evaluation Metrics (on valid responses):\n",
            "ğŸ§® Accuracy : 0.7217\n",
            "âœ… Precision: 0.7037\n",
            "ğŸ” Recall   : 1.0000\n",
            "â­ F1 Score : 0.8261\n",
            "\n",
            "ğŸ“¦ Valid Predictions: 115 / 159 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.5 ğŸ Results Summary â€“ `Phishing Email Data by Type` Dataset\n",
        "\n",
        "#### âœ… Evaluation Metrics (on valid responses):\n",
        "- **Accuracy**: `72.2%`\n",
        "- **Precision**: `70.4%`\n",
        "- **Recall**: `100.0%`\n",
        "- **F1 Score**: `82.6%`\n",
        "- **Valid JSON Responses**: `115 / 159` emails\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  Interpretation:\n",
        "\n",
        "The model achieved **perfect recall**, successfully flagging all phishing, fraud, and commercial spam emails without missing a single threat â€” aligning well with a security-first policy.\n",
        "\n",
        "However, only **72.3% of emails produced valid structured JSON**, which limits full evaluation and raises concerns for deployment in automation pipelines. This points to a common limitation with current large language models: even with strict prompts, structured outputs are not always guaranteed.\n",
        "\n",
        "### âš ï¸ JSON Reliability Issue\n",
        "\n",
        "Despite excellent detection accuracy, **44 emails (27.7%) failed to produce valid JSON**, highlighting :\n",
        "- Long mails could cause a problem for the models, espically the smaller ones.\n",
        "\n",
        "> ğŸ“Œ These results show that while LLMs are highly capable of detecting phishing threats, using them reliably in production workflows requires further handling of output formatting stability.\n"
      ],
      "metadata": {
        "id": "ONfiwv0lNKEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 ğŸ—‚ï¸ Dataset: Improving Phishing Detection Via Psychological Trait Scoring\n",
        "\n",
        "This dataset includes real-world phishing and legitimate emails sourced from:\n",
        "- The ENRON corpus\n",
        "- University phishing simulation archives\n",
        "- Public phishing training sites\n",
        "\n",
        "Each entry includes:\n",
        "- `text`: the full email message (subject + body)\n",
        "- `is_phishing`: ground truth label (`1` = phishing, `0` = legitimate)\n",
        "- `source`: where the email was collected from (e.g., ENRON, Stanford, etc.)\n",
        "\n",
        "Once uploaded, we will:\n",
        "- âœ… Verify label distribution\n",
        "- âœ… Preview email content\n",
        "- âœ… Generate structured prompts for zero-shot LLM inference\n",
        "- âœ… Evaluate model predictions against the `is_phishing` field\n"
      ],
      "metadata": {
        "id": "GXEOfIg5POLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.1 ğŸ—‚ï¸ Upload and Load the `Improving Phishing Detection Via Psychological Trait Scoring` Dataset\n",
        "\n",
        "In this step, we upload and inspect the dataset used in the study *\"Improving Phishing Detection via Psychological Trait Scoring.\"*\n",
        "\n",
        "The dataset contains labeled email samples from multiple sources, including ENRON and university phishing education portals.\n",
        "\n",
        "The structure includes:\n",
        "- `text`: the full email content (subject + body)\n",
        "- `source`: the origin of the email (e.g., ENRON, Stanford, University of Washington)\n",
        "- `is_phishing`: binary label\n",
        "  - `1` = phishing\n",
        "  - `0` = safe/legitimate\n",
        "\n",
        "Once loaded, we will preview the first few entries, confirm the structure, and proceed to standardize and prepare the data for prompt-based inference.\n"
      ],
      "metadata": {
        "id": "mxqHkiSuPvPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§  Section 2.3.1 â€“ Upload and Load the Phishing Email Data by Type Dataset\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# ğŸ“¤ Upload dataset\n",
        "print(\"ğŸ“¤ Please upload the 'phishing_data_by_type.csv' file.\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# âœ… Load dataset\n",
        "df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "print(f\"\\nâœ… Dataset loaded: {file_name}\")\n",
        "print(f\"ğŸ“¦ Rows: {len(df)}\")\n",
        "print(f\"ğŸ§¾ Columns: {df.columns.tolist()}\")\n",
        "\n",
        "# âœ… Preview first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "dDN0BvJIP2Yt",
        "outputId": "f8c602cd-dfa2-46f1-fc20-d05c96e2fde6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¤ Please upload the 'phishing_data_by_type.csv' file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26fac76b-8e46-469d-bb87-25b5758088e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26fac76b-8e46-469d-bb87-25b5758088e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving curated_set.csv to curated_set.csv\n",
            "\n",
            "âœ… Dataset loaded: curated_set.csv\n",
            "ğŸ“¦ Rows: 326\n",
            "ğŸ§¾ Columns: ['Unnamed: 0', 'text', 'source', 'is_phishing']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text  \\\n",
              "0           0  Subject: ena offsite\\nmy suggestions :\\n1 ) mo...   \n",
              "1           1  Subject: allegheny energy s - 3\\ni received wo...   \n",
              "2           2  The University of Washington System is sharing...   \n",
              "3           3  Dear user@stanford.edu,\\n\\nA private document ...   \n",
              "4           4  Subject: james valverde - interview schedule\\n...   \n",
              "\n",
              "                                              source  is_phishing  \n",
              "0                                              ENRON            0  \n",
              "1                                              ENRON            0  \n",
              "2  https://ciso.uw.edu/education/more-phishing-ex...            1  \n",
              "3                  https://uit.stanford.edu/phishing            1  \n",
              "4                                              ENRON            0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-822ffc61-f048-45f2-bb12-83290203e473\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>is_phishing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Subject: ena offsite\\nmy suggestions :\\n1 ) mo...</td>\n",
              "      <td>ENRON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Subject: allegheny energy s - 3\\ni received wo...</td>\n",
              "      <td>ENRON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>The University of Washington System is sharing...</td>\n",
              "      <td>https://ciso.uw.edu/education/more-phishing-ex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Dear user@stanford.edu,\\n\\nA private document ...</td>\n",
              "      <td>https://uit.stanford.edu/phishing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Subject: james valverde - interview schedule\\n...</td>\n",
              "      <td>ENRON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-822ffc61-f048-45f2-bb12-83290203e473')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-822ffc61-f048-45f2-bb12-83290203e473 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-822ffc61-f048-45f2-bb12-83290203e473');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e85ed73a-2e76-4262-a818-3f25638eca1f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e85ed73a-2e76-4262-a818-3f25638eca1f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e85ed73a-2e76-4262-a818-3f25638eca1f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 326,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 94,\n        \"min\": 0,\n        \"max\": 325,\n        \"num_unique_values\": 326,\n        \"samples\": [\n          234,\n          110,\n          249\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 325,\n        \"samples\": [\n          \"Subject: re : personal information needs to be updated\\nis it possible that his first name show as \\\" j darren \\\" ? daren is his middle\\nname and the name that everyone addresses him by .\\nwe would also be glad to submit the change in sap if the system will accept j\\ndarren as the first name .\\nplease advise .\\nthanks for your help , hgm\\nsusan wimberley @ ect\\n11 / 07 / 2000 02 : 12 pm\\nto : hector mcloughlin / corp / enron @ enron\\ncc : dfarmer @ enron . com @ enron\\nsubject : re : personal information needs to be updated\\nplease note that the name in pep has to mirror what is in the source system .\\ncurrently there is not a field in pep for nicknames .\\nenron capital & trade resources corp .\\nfrom : hector mcloughlin @ enron 11 / 07 / 2000 01 : 48 pm\\nto : dfarmer @ enron . com , susan wimberley / hou / ect @ ect\\ncc :\\nsubject : re : personal information needs to be updated\\nsusan ,\\nwould you please take care of mr . farmer ' s request ? i am not able to change\\nnames .\\nthanks for your help , hgm\\ndfarmer @ enron . com on 11 / 07 / 2000 01 : 15 : 08 pm\\nto : hector . mcloughlin @ enron . com\\ncc :\\nsubject : personal information needs to be updated\\nthis message is from farmer , jerry d :\\nmy name should be changed from farmer , jerry d to farmer , j daren\",\n          \"Subject: update on confirmlogic\\ni wanted to give you a quick update on confirmlogic . . . .\\ntesting was done last week on the confirmlogic module . on thursday , we discussed with kathryn cordes and the confirmlogic it team the items that we had found that were \\\" show stoppers \\\" as far as releasing the product for beta testing . some of the major items found were the inability to properly handle basis swaps for gas and inability to display meaningful index references for power ( they were pulling in a code rather than a description of the index ) .\\nthe team worked on the \\\" fixes \\\" and migrated the code last night . today during testing , they found that the new code had actually caused problems with the fixed price and volume information , which was working previously . i talked to kathryn and she said that the were rebuilding the code . she said that someone had tested the fix last night and everything worked fine . we plan more testing in the morning .\\nthey are doing a high - level demo this thursday for beta customers just to introduce the module . they were planning on having more extensive beta demos for each client starting next week but realize that those may have to postponed further .\\nwe have told them that we would not sign off for beta testing until we were comfortable that the items that we identified were working . we need consistent , stable days of testing before i will feel comfortable .\\noverall , we like the \\\" new \\\" streamlined version of the screens and feel that it will be a good product if they can work out the data display issues .\\ncall with any questions .\\nkim theriot\",\n          \"Subject: tables report - 9 / 25 / 01\\nplease see the attached . if you would like to be removed from this distribution , please let me know .\\nthanks ,\\nkathy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"https://ciso.uw.edu/education/more-phishing-examples/\",\n          \"https://lts.lehigh.edu/phishing/examples\",\n          \"ENRON\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_phishing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.2 ğŸ§  Preprocess Dataset and Generate Structured Prompts\n",
        "\n",
        "In this step, we prepare the `Improving Phishing Detection Via Psychological Trait Scoring` dataset for model inference by:\n",
        "\n",
        "- Renaming the column `is_phishing` to `label` for consistency\n",
        "- Ensuring the `text` field is used as the full email body\n",
        "- Generating a structured, instruction-following prompt for each email\n",
        "- Appending the prompt in a new column `prompt` for batch inference\n",
        "\n",
        "Each prompt is designed to instruct the model to return a detailed phishing risk assessment in strict JSON format.\n"
      ],
      "metadata": {
        "id": "sEO5qxAjP2_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§  Section 2.4.2 â€“ Preprocess and Generate Structured Prompts\n",
        "\n",
        "# âœ… Standardize label column name\n",
        "df = df.rename(columns={\"is_phishing\": \"label\"})\n",
        "\n",
        "# âœ… Prompt generation function\n",
        "def build_prompt(email_body):\n",
        "    return f\"\"\"### Instruction:\n",
        "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
        "\n",
        "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
        "\n",
        "- A link to a document/file from an unfamiliar or suspicious domain\n",
        "- Urgent language or pressure to act quickly\n",
        "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
        "- Requests to click, download, or input sensitive data\n",
        "- Email sender addresses mimicking known brands or internal departments\n",
        "- Unexpected attachments or shared documents\n",
        "- Impersonation of executives, HR, IT, or Finance\n",
        "- Spelling mistakes or inconsistencies in formatting\n",
        "\n",
        "### Respond in **this exact JSON format**:\n",
        "{{\n",
        "  \"Is_Phishing\": boolean,\n",
        "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
        "  \"Suspicious_Links\": [\"...\"],\n",
        "  \"Social_Engineering_Elements\": [\"...\"],\n",
        "  \"Actions\": [\"...\"],\n",
        "  \"Reason\": \"...\"\n",
        "}}\n",
        "\n",
        "### Email:\n",
        "{email_body}\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "# âœ… Apply prompt generator\n",
        "df[\"prompt\"] = df[\"text\"].apply(build_prompt)\n",
        "\n",
        "# âœ… Preview a sample phishing prompt\n",
        "sample_index = df[df[\"label\"] == 1].sample(1, random_state=42).index[0]\n",
        "print(\"\\nğŸ“Œ Full Prompt Example (Phishing Email):\\n\")\n",
        "print(df.loc[sample_index, \"prompt\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSI0xToXP_Q1",
        "outputId": "d5fa024e-7320-46bb-c172-3f48b3a6d9af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Œ Full Prompt Example (Phishing Email):\n",
            "\n",
            "### Instruction:\n",
            "You are a cybersecurity expert working in a company's Security Operations Center (SOC).\n",
            "\n",
            "Your task is to analyze the following email and return a structured JSON response. Be extremely strict and assume worst-case risk posture when any of the following are present:\n",
            "\n",
            "- A link to a document/file from an unfamiliar or suspicious domain\n",
            "- Urgent language or pressure to act quickly\n",
            "- Generic greetings (\"Hi\", \"Dear user\") with no name\n",
            "- Requests to click, download, or input sensitive data\n",
            "- Email sender addresses mimicking known brands or internal departments\n",
            "- Unexpected attachments or shared documents\n",
            "- Impersonation of executives, HR, IT, or Finance\n",
            "- Spelling mistakes or inconsistencies in formatting\n",
            "\n",
            "### Respond in **this exact JSON format**:\n",
            "{\n",
            "  \"Is_Phishing\": boolean,\n",
            "  \"Risk\": \"High\" | \"Medium\" | \"Low\",\n",
            "  \"Suspicious_Links\": [\"...\"],\n",
            "  \"Social_Engineering_Elements\": [\"...\"],\n",
            "  \"Actions\": [\"...\"],\n",
            "  \"Reason\": \"...\"\n",
            "}\n",
            "\n",
            "### Email:\n",
            "1 New Payroll Stanford CS Message\n",
            "\n",
            "Click https://cs.stanford.edu/hr/payroll.php to READ\n",
            "\n",
            "Human Resources & Payroll Service\n",
            "Stanford CS - Stanford University\n",
            "\n",
            "### Response:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.3 ğŸ¤– Run Batched Inference and Extract Structured JSON Output\n",
        "\n",
        "In this step, we process each structured prompt using a large language model (e.g., Mistral-7B) in batches.\n",
        "\n",
        "This involves:\n",
        "- Tokenizing prompts with appropriate padding and truncation\n",
        "- Generating structured responses using `inference_mode()` for performance\n",
        "- Decoding model outputs and extracting JSON blocks using regex\n",
        "- Parsing each structured JSON response and appending it to the dataset\n",
        "\n",
        "The results are stored in a new `model_output` column for further evaluation.\n"
      ],
      "metadata": {
        "id": "GSSFe9TYQD7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import inference_mode\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import json\n",
        "\n",
        "# ğŸ”§ Inference configuration\n",
        "batch_size = 16\n",
        "max_prompt_length = 2048\n",
        "max_new_tokens = 2048\n",
        "all_predictions = []\n",
        "\n",
        "# ğŸ§¹ Clear previous predictions in case re-running\n",
        "all_predictions.clear()\n",
        "print(f\"ğŸ” Running batched inference (batch size = {batch_size})...\")\n",
        "\n",
        "# ğŸ”„ Batched inference loop\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    batch_prompts = df[\"prompt\"].iloc[i:i+batch_size].tolist()\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_prompt_length).to(\"cuda\")\n",
        "\n",
        "    with inference_mode():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.0,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode and extract structured JSON\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    for decoded in decoded_outputs:\n",
        "        matches = list(re.finditer(r\"\\{[\\s\\S]+?\\}\", decoded))\n",
        "        json_text = max(matches, key=lambda m: len(m.group())).group() if matches else \"\"\n",
        "        try:\n",
        "            parsed = json.loads(json_text) if json_text else {\"error\": \"no_json_found\", \"raw\": decoded}\n",
        "        except:\n",
        "            parsed = {\"error\": \"invalid_json\", \"raw\": decoded}\n",
        "        all_predictions.append(parsed)\n",
        "\n",
        "# âœ… Final check before assignment\n",
        "if len(all_predictions) != len(df):\n",
        "    print(f\"âŒ Mismatch: predictions ({len(all_predictions)}) vs rows ({len(df)})\")\n",
        "else:\n",
        "    df[\"model_output\"] = all_predictions\n",
        "    print(\"âœ… Batched inference complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwoAY2nZQEhF",
        "outputId": "59d70551-127b-48b4-ce41-eb3635080089"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Running batched inference (batch size = 16)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/21 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [12:49<00:00, 36.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Batched inference complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.4 ğŸ“Š Inference Results Summary and Evaluation\n",
        "\n",
        "After running inference on the `Improving Phishing Detection Via Psychological Trait Scoring` dataset, we now compare the modelâ€™s predictions to the ground truth labels.\n",
        "\n",
        "This step involves:\n",
        "- Extracting the `Is_Phishing` field from the model's JSON response\n",
        "- Comparing it with the `label` column\n",
        "- Calculating evaluation metrics:\n",
        "  - Accuracy\n",
        "  - Precision\n",
        "  - Recall\n",
        "  - F1 Score\n",
        "- Assessing how well the model balances threat detection vs. false positives\n",
        "\n",
        "> ğŸ“Œ These metrics help evaluate model effectiveness in identifying socially engineered emails while avoiding misclassification of safe content.\n"
      ],
      "metadata": {
        "id": "0U2khW07Q3DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# âœ… Extract model-predicted labels\n",
        "def extract_prediction(obj):\n",
        "    if isinstance(obj, dict) and \"Is_Phishing\" in obj:\n",
        "        return int(obj[\"Is_Phishing\"]) if isinstance(obj[\"Is_Phishing\"], bool) else None\n",
        "    return None\n",
        "\n",
        "df[\"predicted_label\"] = df[\"model_output\"].apply(extract_prediction)\n",
        "\n",
        "# âœ… Filter for valid predictions\n",
        "valid = df.dropna(subset=[\"predicted_label\"])\n",
        "y_true = valid[\"label\"]\n",
        "y_pred = valid[\"predicted_label\"]\n",
        "\n",
        "# âœ… Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# âœ… Summary\n",
        "print(\"ğŸ“Š Evaluation Metrics (on valid responses):\")\n",
        "print(f\"ğŸ§® Accuracy : {accuracy:.4f}\")\n",
        "print(f\"âœ… Precision: {precision:.4f}\")\n",
        "print(f\"ğŸ” Recall   : {recall:.4f}\")\n",
        "print(f\"â­ F1 Score : {f1:.4f}\")\n",
        "print(f\"\\nğŸ“¦ Valid Predictions: {len(valid)} / {len(df)} total\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUnkSP1kQ4Om",
        "outputId": "9887eb58-7eee-4f4b-abb2-06d14ed910f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Evaluation Metrics (on valid responses):\n",
            "ğŸ§® Accuracy : 0.6554\n",
            "âœ… Precision: 0.5941\n",
            "ğŸ” Recall   : 0.9877\n",
            "â­ F1 Score : 0.7419\n",
            "\n",
            "ğŸ“¦ Valid Predictions: 325 / 326 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.5 ğŸ Results Summary â€“ `Improving Phishing Detection Via Psychological Trait Scoring` Dataset\n",
        "\n",
        "#### âœ… Evaluation Metrics (on valid responses):\n",
        "- **Accuracy**: `65.5%`\n",
        "- **Precision**: `59.4%`\n",
        "- **Recall**: `98.8%`\n",
        "- **F1 Score**: `74.2%`\n",
        "- **Valid JSON Responses**: `325 / 326` emails\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  Interpretation:\n",
        "\n",
        "The model achieved **exceptional recall**, successfully detecting nearly every phishing email, making it highly effective for use in environments where **false negatives are unacceptable**.\n",
        "\n",
        "However, with a **precision of 59.4%**, a noticeable number of legitimate emails we\n"
      ],
      "metadata": {
        "id": "dGmDmbQ4U2_T"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP/i2MupMWgsxyUzHhX+xQ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "333b3e9d7735400a8ad97f0f6025d96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf13d79f97914ad992b0cfad5df8e90a",
              "IPY_MODEL_f0ae4bff45cd42a88cdac453150b1f8b",
              "IPY_MODEL_aded7e968a584b1eac9a2f3709d1b02d"
            ],
            "layout": "IPY_MODEL_330bd12d9d3a45fc87e50adad276739d"
          }
        },
        "cf13d79f97914ad992b0cfad5df8e90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f001d160164663ba3a03c4ce991be3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f8a3b8c9fb9045559aea802fd1cb88de",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "f0ae4bff45cd42a88cdac453150b1f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_371b3f75f00c434daacbce493e99ea2a",
            "max": 140911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47e219e42cb441c581d49af3925d731b",
            "value": 140911
          }
        },
        "aded7e968a584b1eac9a2f3709d1b02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fe213b7cdb8438f85cd6e27c270db9e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_389004b705dd40149df67dae243966d3",
            "value": "â€‡141k/141kâ€‡[00:00&lt;00:00,â€‡11.6MB/s]"
          }
        },
        "330bd12d9d3a45fc87e50adad276739d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f001d160164663ba3a03c4ce991be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8a3b8c9fb9045559aea802fd1cb88de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "371b3f75f00c434daacbce493e99ea2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e219e42cb441c581d49af3925d731b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fe213b7cdb8438f85cd6e27c270db9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "389004b705dd40149df67dae243966d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5ffa24ba26f421cbc8bd6011d2b0372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b596788178dc49af87cc176efa61de4c",
              "IPY_MODEL_828512fad88d4e5bad12685ba4f74359",
              "IPY_MODEL_e138ad2c07eb4ac285087cdc90e55fe1"
            ],
            "layout": "IPY_MODEL_7ce0d531f73a4d30bd4d8ab7d41415b9"
          }
        },
        "b596788178dc49af87cc176efa61de4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77a34bfa6b004c7684552e43a02c80e5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d781437ee00443aba2d01a71b1cc1131",
            "value": "tokenizer.model:â€‡100%"
          }
        },
        "828512fad88d4e5bad12685ba4f74359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fdf7279e28644d4b0430f35b7d04757",
            "max": 587404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c10e8ba69dd04fdbaeab7933b8eb56fe",
            "value": 587404
          }
        },
        "e138ad2c07eb4ac285087cdc90e55fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d28f814b5d4c9fb410788ccf9c263d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3369fa1af6cc4fb0822cc0d796c7eabe",
            "value": "â€‡587k/587kâ€‡[00:00&lt;00:00,â€‡18.8MB/s]"
          }
        },
        "7ce0d531f73a4d30bd4d8ab7d41415b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a34bfa6b004c7684552e43a02c80e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d781437ee00443aba2d01a71b1cc1131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fdf7279e28644d4b0430f35b7d04757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c10e8ba69dd04fdbaeab7933b8eb56fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d28f814b5d4c9fb410788ccf9c263d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3369fa1af6cc4fb0822cc0d796c7eabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521dd20ca4bc462ebf5aa852e9cf71ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa1aa6a384634044adce493f46ee3b56",
              "IPY_MODEL_ff4c0db6726d4884b43410bd247cf4ad",
              "IPY_MODEL_946e859edee848b88ca00e0b7fb1ad31"
            ],
            "layout": "IPY_MODEL_155efaf089c445879dcd03739cdb3909"
          }
        },
        "fa1aa6a384634044adce493f46ee3b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_873f9c34aa6442bd8366c69d73a1bed7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c5cb7f0863f64ff8a58c278140bb7b8b",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "ff4c0db6726d4884b43410bd247cf4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7b66dad5c34109b44db0d50098dc18",
            "max": 1961548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c081f69e7255487ea7cb49392d3c4671",
            "value": 1961548
          }
        },
        "946e859edee848b88ca00e0b7fb1ad31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17227db628b64614bc8b99a0b40d35e4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_705e3fde92e541c98321346486670f5c",
            "value": "â€‡1.96M/1.96Mâ€‡[00:00&lt;00:00,â€‡4.42MB/s]"
          }
        },
        "155efaf089c445879dcd03739cdb3909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "873f9c34aa6442bd8366c69d73a1bed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5cb7f0863f64ff8a58c278140bb7b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c7b66dad5c34109b44db0d50098dc18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c081f69e7255487ea7cb49392d3c4671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17227db628b64614bc8b99a0b40d35e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "705e3fde92e541c98321346486670f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e786b87a4dd4b6ca9e6edad672ee149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64afbf39f26c4016a9ea44ad4fbb389f",
              "IPY_MODEL_f179d13bafd84965b245a8ad9df9cd24",
              "IPY_MODEL_77ecaf44afbb47f9b071d8e43395ce97"
            ],
            "layout": "IPY_MODEL_ecce06ad660f4c50834598d27c830731"
          }
        },
        "64afbf39f26c4016a9ea44ad4fbb389f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_320bfbecfd49467aa4654c380e8483ba",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_39776ac2b4e74d3aad5e7af6574833b1",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "f179d13bafd84965b245a8ad9df9cd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71f817877fbd4c63929754e1dadfed7f",
            "max": 446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c89cd14812d405099be715ef2dffa24",
            "value": 446
          }
        },
        "77ecaf44afbb47f9b071d8e43395ce97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc83457376342fca76ac9940ed5d762",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f88c249f869e4540b50254ce9b914090",
            "value": "â€‡446/446â€‡[00:00&lt;00:00,â€‡56.2kB/s]"
          }
        },
        "ecce06ad660f4c50834598d27c830731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "320bfbecfd49467aa4654c380e8483ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39776ac2b4e74d3aad5e7af6574833b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71f817877fbd4c63929754e1dadfed7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c89cd14812d405099be715ef2dffa24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fc83457376342fca76ac9940ed5d762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f88c249f869e4540b50254ce9b914090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a6908d000ad41cf9de97f9d3d495a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d4c95a3c87e4f7b93dd47b1e7910b7c",
              "IPY_MODEL_069d140614e24b7a91d5d72c004fbc09",
              "IPY_MODEL_31a13e2fbaed45f9bf4cf19fae19522f"
            ],
            "layout": "IPY_MODEL_bace069490bb4cdb9ab240e472f715fa"
          }
        },
        "0d4c95a3c87e4f7b93dd47b1e7910b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd48d62d1c2a46e288434700cd79b0dc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d6d7ce1a97b244f9bd42439ef65de0cb",
            "value": "config.json:â€‡100%"
          }
        },
        "069d140614e24b7a91d5d72c004fbc09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce54d246723242719fac1b1c5b117c52",
            "max": 1205,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04d14484a58449ed972a469dde1b64ae",
            "value": 1205
          }
        },
        "31a13e2fbaed45f9bf4cf19fae19522f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7fad0c668124c50bdefed809fd5322a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_87d76f2620f04c789654f8e45bf126b5",
            "value": "â€‡1.21k/1.21kâ€‡[00:00&lt;00:00,â€‡153kB/s]"
          }
        },
        "bace069490bb4cdb9ab240e472f715fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd48d62d1c2a46e288434700cd79b0dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d7ce1a97b244f9bd42439ef65de0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce54d246723242719fac1b1c5b117c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d14484a58449ed972a469dde1b64ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7fad0c668124c50bdefed809fd5322a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d76f2620f04c789654f8e45bf126b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e8c99d9066d43f8864d233caf20a091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8c9fba57bdf4bca9ea15a068bde2778",
              "IPY_MODEL_41f2651db12c46299e9ed3fa4bd69919",
              "IPY_MODEL_1aac90379f874c36acb9d3f0e00cf12c"
            ],
            "layout": "IPY_MODEL_35b0eae09c5940faa259d0033d76166d"
          }
        },
        "c8c9fba57bdf4bca9ea15a068bde2778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a981c003aa3406984a29354abcf8b9e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9811499857804620880ab7c205380f3c",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "41f2651db12c46299e9ed3fa4bd69919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9288ffab4b48bbbab3b06c853f3ab0",
            "max": 4138270819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d14fd00f4b24519b9a5ee4960e8251e",
            "value": 4138270819
          }
        },
        "1aac90379f874c36acb9d3f0e00cf12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a0ca01a88514c1699ff9452c67dcb19",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_29a4452cf9fb4729b379490a503948a5",
            "value": "â€‡4.14G/4.14Gâ€‡[00:13&lt;00:00,â€‡265MB/s]"
          }
        },
        "35b0eae09c5940faa259d0033d76166d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a981c003aa3406984a29354abcf8b9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9811499857804620880ab7c205380f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de9288ffab4b48bbbab3b06c853f3ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d14fd00f4b24519b9a5ee4960e8251e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a0ca01a88514c1699ff9452c67dcb19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a4452cf9fb4729b379490a503948a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e838a521d01d4fddbc6441bbd5e9fc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_653f82f4bc6f4747a9d2b3b02eeb24b8",
              "IPY_MODEL_34c1066c37954cacb0c455d4ba9619df",
              "IPY_MODEL_6e293a74191b48299f2f25815e455239"
            ],
            "layout": "IPY_MODEL_dae2dda3b7064795bf5e96edbcf79390"
          }
        },
        "653f82f4bc6f4747a9d2b3b02eeb24b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47a2a0adfda7490fbc33acff8564f69a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d02039fa9b8b4e4395c2a12368a3fe8c",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "34c1066c37954cacb0c455d4ba9619df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92571421bd54f808fed1c07cad611b0",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_509229ee597c40418a2dd8efdead4365",
            "value": 157
          }
        },
        "6e293a74191b48299f2f25815e455239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3698470463e04fe2982395da9d9dc70c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e280aef45ef9435392448ed4479bb111",
            "value": "â€‡157/157â€‡[00:00&lt;00:00,â€‡19.4kB/s]"
          }
        },
        "dae2dda3b7064795bf5e96edbcf79390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a2a0adfda7490fbc33acff8564f69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d02039fa9b8b4e4395c2a12368a3fe8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a92571421bd54f808fed1c07cad611b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509229ee597c40418a2dd8efdead4365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3698470463e04fe2982395da9d9dc70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e280aef45ef9435392448ed4479bb111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}